{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b03a30-03dc-4bee-a58d-7e1e2d519c31",
   "metadata": {},
   "source": [
    "# Transform collected YouTube Files to Trainingsdata\n",
    "We want to use two kinds of trainingdata. First we want to split every song in junks of circa 0.5 seconds and use them as trainingsdata to generate new junks. These junks get sorted in a 2 dimensional field by our autoencoder. The structure of a song can then be imagened as a movement trough the 2 dimensional field. We will store these \"movements\", i.e. a list of coordinates and use these lists as trainingsdata for another network. Finally we want to be able to generate new \"movements\", i.e. new sequences of waveset-junks on the one hand and the corresponding junks themselves on the other hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b178d-388a-4b90-8023-6bddbdd2056d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wavesets\n",
    "Every track from the training data gets split in wavesets with a duration of aprox. 0.2 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85c7cd-5c4a-484e-8cdc-3d8268ffdf51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "from IPython.display import display, Audio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af0b3f-2bc6-4070-bcc0-1dc69dc91c26",
   "metadata": {},
   "source": [
    "### Waveset class\n",
    "We split each song in multiple wavesets and create spectograms of them.\n",
    "To train the autoencoder all spectograms have to be of the same size and have an even number of time-windows. The wavesets are of variable length, because the zero-crossing is a contigent feature. We can't be sure that all spectograms have the same number of time-windows. We have to check and pad if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40e759-b53c-414c-b89c-95f30e39a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavesets:\n",
    "    def __init__(self, path, min_size_fraction):\n",
    "            self.data, self.sr = librosa.load(path, sr = None, mono = True)\n",
    "            self.min_size = self.sr/min_size_fraction\n",
    "            self.deleted_ws = 0\n",
    "\n",
    "    def get_splitPoints(self, data):\n",
    "        split_points = np.argwhere(\n",
    "        (np.sign(data[:-1])==-1) & (np.sign(data[1:])==1)\n",
    "        )\n",
    "        return split_points\n",
    "    \n",
    "    def plot_wavesets(self, data, split_points, plot_range):\n",
    "        data_range = data[plot_range[0]:plot_range[1]]\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(data_range)\n",
    "        plt.hlines(0.0, plot_range[0], plot_range[1], color='r')\n",
    "        plt.vlines(split_points[(plot_range[0]<split_points) & (split_points<plot_range[1])], data_range.max(), data_range.min(), color='g')\n",
    "        plt.xlabel(\"samples\")\n",
    "        plt.ylabel(\"amplitude\")\n",
    "        plt.title(\"Wavesets\")\n",
    "        plt.show();\n",
    "        \n",
    "    def resize_splits(self, splits, min_size):\n",
    "        new_splits = []\n",
    "        last_split = 0\n",
    "        for split in splits:\n",
    "            if (split - last_split) > min_size:\n",
    "                last_split = split\n",
    "                new_splits.append(split)\n",
    "        return np.array(new_splits)\n",
    "    \n",
    "\n",
    "    def generate_wavesets(self, data, split_points):\n",
    "        wavesets = []\n",
    "        # we iterate over split points 2 times: once with no offset\n",
    "        # and a 2nd time with an offset of 1 which gives us\n",
    "        # the start and the end - zip allows us to iterate\n",
    "        # over a collection of arrays in parallel\n",
    "        for start, end in zip(split_points[:-1, 0], split_points[1:, 0]):\n",
    "            waveset = data[start:end+1]\n",
    "            waveset = self.apply_padding(waveset,(int(self.min_size + (self.sr*0.04))))\n",
    "            if type(waveset) is np.ndarray:\n",
    "                wavesets.append(waveset)\n",
    "        return wavesets\n",
    "    \n",
    "    def get_Wavesets(self):\n",
    "        split_points = self.get_splitPoints(self.data)\n",
    "        split_points = self.resize_splits(split_points, self.min_size)\n",
    "        #self.plot_wavesets(data, split_points, plot_range=[0, self.sr * 60 * 7])\n",
    "        wavesets = self.generate_wavesets(self.data, split_points)\n",
    "        wavesets = self.get_waveset_spectos(wavesets)\n",
    "        return wavesets\n",
    "    \n",
    "    def get_waveset_spectos(self, wavesets):\n",
    "        spectograms = []\n",
    "        for ws in wavesets:\n",
    "            spectogram = librosa.feature.melspectrogram(y=ws, sr=self.sr, hop_length=HOP_LENGTH, win_length=WIN_LENGTH, n_fft=N_FFT)\n",
    "            spectogram = librosa.amplitude_to_db(spectogram)\n",
    "            spectogram = spectogram[... , np.newaxis]\n",
    "            spectograms.append(spectogram)\n",
    "        return spectograms\n",
    "    \n",
    "    def apply_padding(self, waveset, max_length):\n",
    "        missing_vals = max_length - waveset.shape[0]\n",
    "        \n",
    "        if missing_vals >= 0:\n",
    "            waveset = np.pad(waveset, (0 , missing_vals), 'constant', constant_values=(0,0))\n",
    "            return waveset\n",
    "        else:\n",
    "            #print(f\"WARNING: One Waveset is too long: {path}. It has {-missing_vals} more samples then max_length and gets dropped.\")\n",
    "            self.deleted_ws += 1\n",
    "            return None\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034fc825-5c3e-488b-ad1e-d278c40e6e84",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate Wavesets\n",
    "We can now generate all Wavesets. Later we want to be able to reconstruct the position of each waveset in the song. For this, we store how many wavesets each song is split into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f42a2-6e32-4001-9692-352c17d65660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "WIN_LENGTH = int(sr/30)\n",
    "HOP_LENGTH = int(sr/60)\n",
    "N_FFT = int(sr/20)\n",
    "\n",
    "\n",
    "folder_path = 'H:\\Musik\\CD-Sammlung wavs\\Music'\n",
    "paths = librosa.util.find_files(folder_path, ext=['wav'])\n",
    "\n",
    "all_wavesets = []\n",
    "num_of_ws_per_song = []\n",
    "deleted_wavesets = 0\n",
    "\n",
    "for i,path in enumerate(paths): \n",
    "    waveset_generator = Wavesets(path, 2)\n",
    "    wavesets = waveset_generator.get_Wavesets() # The variable \"wavesets\" is a list of np-arrays (with the amplitudes stored in it).\n",
    "    deleted_wavesets += waveset_generator.deleted_ws\n",
    "    all_wavesets.extend(list(wavesets))  # all wavesets is a list of all wavesets\n",
    "    num_of_ws_per_song.append(len(wavesets)) # a list of the number of wavesets each song has\n",
    "    print(f\"{i+1} of {len(paths)} songs done.\" + f\" Currently working on file:{path}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa68a9-739a-4ad4-9947-0632911ef4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We've extracted {len(all_wavesets)} wavesets out of {len(paths)} songs.\")\n",
    "print(f\"We had to delete {deleted_wavesets} wavesets, because they were too long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d855344-5dd0-4d01-a7b0-f2ee26d7ffc8",
   "metadata": {},
   "source": [
    "We can double check, that all spectograms have the same shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb7751-3158-4d57-b7d7-cd007a32c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ws in enumerate(all_wavesets):\n",
    "    if not (ws.shape == all_wavesets[0].shape):\n",
    "        #print(\"Something went wrong!\")\n",
    "        print(f\"{ws.shape[0] - all_wavesets[0].shape[0]} in dim 0 and {ws.shape[1]- all_wavesets[1].shape[1]} in dim 1\")\n",
    "        print(f\"Error occured in waveset {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a5374-1043-4b9a-8967-15c0d25bd488",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can look at the spectogram of a random waveset to see that everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4922a-ee39-4b2d-824f-645f2f8c795b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "librosa.display.specshow(\n",
    "    all_wavesets[np.random.randint(0,len(all_wavesets))].reshape(all_wavesets[0].shape[0],all_wavesets[0].shape[1]),\n",
    "    x_axis='time',\n",
    "    y_axis='mel',\n",
    "    sr=sr,\n",
    "    fmax=20000,\n",
    "    hop_length=HOP_LENGTH,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a724970-8858-43fd-b282-1aee8d318b01",
   "metadata": {},
   "source": [
    "We do not normalize our samples, because we want to preserve the loudness of each waveset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c86468-8d15-41bd-9e2a-523a6073994e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Song-Label for Wavesets\n",
    "We need another array that stores the information which waveset belongs to which song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd429aca-875a-4b7d-9898-96a69e763da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song_labels = np.empty(len(all_wavesets))\n",
    "\n",
    "start_ws = 0\n",
    "stop_ws = 0\n",
    "\n",
    "for i, num_of_ws in enumerate(num_of_ws_per_song):\n",
    "    stop_ws += num_of_ws\n",
    "    song_labels[start_ws : stop_ws] = i\n",
    "    start_ws += num_of_ws\n",
    "    print(f\"{((i+1)/len(num_of_ws_per_song)) * 100}% done\", end = \"\\r\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2328f-3f5c-4307-af52-80f3b66dcd8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create position data\n",
    "We also want to know, at which position in the song a waveset occured. For this we split the song in 4 parts and create a label 0,1,2 or 3 for each waveset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54205bc-fe76-434b-beb8-5c4e663ea4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "position_labels = np.empty(len(all_wavesets))\n",
    "\n",
    "start_ws = 0\n",
    "stop_ws = 0\n",
    "\n",
    "for i, num_of_ws in enumerate(num_of_ws_per_song):\n",
    "    for j in range(4):\n",
    "        stop_ws += int((num_of_ws/4))\n",
    "        position_labels[start_ws : stop_ws] = j+1\n",
    "        start_ws = stop_ws\n",
    "    print(f\"{((i+1)/len(num_of_ws_per_song)) * 100}% done\", end = \"\\r\")\n",
    "\n",
    "position_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ddfd9-e4f5-4d3c-8075-3f7a6919f8b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save Data\n",
    "We save the data on disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44108395-28a1-4cb5-8c95-4da503b98892",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data\\spectos.npy\"\n",
    "np.save(save_path,all_wavesets)\n",
    "\n",
    "save_path2 = \"data\\song_labels.npy\"\n",
    "np.save(save_path2, song_labels)\n",
    "\n",
    "save_path3 = \"data\\position_labels.npy\"\n",
    "np.save(save_path3, position_labels)\n",
    "\n",
    "save_path4 = \"data\\num_of_ws_per_song.npy\"\n",
    "np-save(save_path4, num_of_ws_per_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257a61b-bc8e-47eb-bec0-fbc37968a014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
