{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab5e0cd-f754-4481-a167-13b6872f7774",
   "metadata": {},
   "source": [
    "# Transform collected YouTube Files to Trainingsdata\n",
    "We want to use two kinds of trainingdata. First we want to split every song in junks of circa 1 second. These junks get sorted by similarity and then labeled accordingly. We will use these junks as trainingdata to create new junks of audio. Additionally we want to store the order of junk-lables. This order will be used to create a new orders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c497dc-be01-47ce-89c8-d8060758f4f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wavesets\n",
    "Every track from the training data gets split in wavesets with a duration of aproximattly 1 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b07b5f0-8af1-4c80-8cfd-3cc7236356b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b16153b-6909-40a3-923b-87b226c54d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43b2ae-170e-4496-8faa-0ff65178b891",
   "metadata": {},
   "source": [
    "### Loading data (demo track):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75627e6d-ffb6-403a-a722-c48805f52662",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     data, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(path, sr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, mono \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     songs\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m----> 8\u001b[0m \u001b[43msongs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "folder_path = 'demoData'\n",
    "paths = librosa.util.find_files(folder_path, ext=['wav']) \n",
    "songs = []\n",
    "\n",
    "for path in paths: \n",
    "    data, sr = librosa.load(path, sr = None, mono = True)\n",
    "    songs.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3ad63-9c16-4a69-b441-f4116eb565e6",
   "metadata": {},
   "source": [
    "### Waveset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f077b894-5632-4c4d-bf54-92bd14454ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavesets:\n",
    "    def __init__(self, audio_data, sample_rate):\n",
    "            self.data = audio_data\n",
    "            self.sr = sample_rate\n",
    "    \n",
    "    def get_splitPoints(self, data):\n",
    "        split_points = np.argwhere(\n",
    "        (np.sign(data[:-1])==-1) & (np.sign(data[1:])==1)\n",
    "        )\n",
    "        return split_points\n",
    "    \n",
    "    def plot_wavesets(self, data, split_points, plot_range):\n",
    "        data_range = data[plot_range[0]:plot_range[1]]\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(data_range)\n",
    "        plt.hlines(0.0, plot_range[0], plot_range[1], color='r')\n",
    "        plt.vlines(split_points[(plot_range[0]<split_points) & (split_points<plot_range[1])], data_range.max(), data_range.min(), color='g')\n",
    "        plt.xlabel(\"samples\")\n",
    "        plt.ylabel(\"amplitude\")\n",
    "        plt.title(\"Wavesets\")\n",
    "        plt.show();\n",
    "        \n",
    "    def resize_splits(self, splits, min_size):\n",
    "        new_splits = []\n",
    "        last_split = 0\n",
    "        for split in splits:\n",
    "            if (split - last_split) > min_size:\n",
    "                last_split = split\n",
    "                new_splits.append(split)\n",
    "        return np.array(new_splits)\n",
    "    \n",
    "\n",
    "    def generate_wavesets(self, data, split_points):\n",
    "        wavesets = []\n",
    "        # we iterate over split points 2 times: once with no offset\n",
    "        # and a 2nd time with an offset of 1 which gives us\n",
    "        # the start and the end - zip allows us to iterate\n",
    "        # over a collection of arrays in parallel\n",
    "        for start, end in zip(split_points[:-1, 0], split_points[1:, 0]):\n",
    "            wavesets.append(data[start:end+1])\n",
    "            \n",
    "        return wavesets\n",
    "    \n",
    "    def get_Wavesets(self):\n",
    "        split_points = self.get_splitPoints(self.data)\n",
    "        split_points = self.resize_splits(split_points, self.sr*2)\n",
    "        #self.plot_wavesets(data, split_points, plot_range=[0, self.sr * 60 * 7])\n",
    "        wavesets = self.generate_wavesets(self.data, split_points)\n",
    "        return wavesets\n",
    "    \n",
    "    @classmethod\n",
    "    def enumerate_Wavesets(self, wavesets):\n",
    "        enum_wavesets = []\n",
    "        num = 0\n",
    "        for ws in wavesets:\n",
    "            enum_wavesets.append([ws, num])\n",
    "            num = num+1\n",
    "        return enum_wavesets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15e9cc-911e-41c0-90bb-54b1784c50ac",
   "metadata": {},
   "source": [
    "### Generate Wavesets\n",
    "We can now generate all Wavesets. We also store their position in the song for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7acbd3c6-f0ec-4eba-89e2-a69e7e11510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavesets = []\n",
    "\n",
    "for song in songs:\n",
    "    wavesets = Wavesets(song, sr).get_Wavesets()\n",
    "    enum_wavesets = Wavesets.enumerate_Wavesets(wavesets) # the position in the song gets stored as an integer-value. The data has now this structure: [[amplitude, amplitude, amplitude],position_in_song]]\n",
    "    all_wavesets.append(enum_wavesets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af9a27-8cd8-4099-b14c-36a079efd64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bbedde2-fd9c-437b-8ab7-2cf45f6b93ad",
   "metadata": {},
   "source": [
    "## Label wavesets\n",
    "The wavesets of all songs get ordered by similiarity. After that they get split in 1000 categories, i.e. they get labeled with a value between 0-999."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bcf95-6c52-4910-96e4-faa969328a8c",
   "metadata": {},
   "source": [
    "First we create the spectrogram of each waveset. For this we use the FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4583f128-2622-4bc0-a4be-a5f8ca9563f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_wavesets(wavesets, n_fft, hop_length, win_length):\n",
    "    fft_data = []\n",
    "    for ws in wavesets:\n",
    "        fft = librosa.stft(data, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "        fft_data.append(fft)\n",
    "    return fft_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea3404cc-3eab-4c63-af25-2f5b1e2bcd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LENGTH = int(sr/4)\n",
    "HOP_LENGTH = int(sr/6)\n",
    "N_FFT = int(sr/2)\n",
    "\n",
    "for waveset in all_wavesets:\n",
    "    fft_data = fft_wavesets(waveset[0], N_FFT, HOP_LENGTH, WIN_LENGTH)\n",
    "    waveset[0] = fft_data # We replace the PCM-data with FFT-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0926b54-49e8-4812-917f-4d2b8a556b26",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mall_wavesets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f862baf-073c-4430-b5fb-7ac5f8899943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
