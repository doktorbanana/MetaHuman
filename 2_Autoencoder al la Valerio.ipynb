{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae2036a-a6cd-4ffb-93d9-588ec932d76d",
   "metadata": {},
   "source": [
    "# Autoencoder nach Valerio\n",
    "We build a mirrored deep convultional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8f41bf-73a3-4c35-b635-07a65a4e2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc776b83-cf71-4fde-8c85-56cf1693ea7b",
   "metadata": {},
   "source": [
    "## Build the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa736ba-69d8-4090-83f6-2a0ef1b33d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    \n",
    "    def __init__(self, input_shape, conv_filters, conv_kernels, conv_strides, latent_space_dim):\n",
    "        self.input_shape = input_shape # dimension of input data: frequency-bins, time-windows, amplitude\n",
    "        self.conv_filters = conv_filters # a list with the number of filters per layer\n",
    "        self.conv_kernels = conv_kernels # a list with the kernel size per layer\n",
    "        self.conv_strides = conv_strides # a list with the strides per layer\n",
    "        self.latent_space_dim = latent_space_dim\n",
    "        self._shape_before_bottleneck = None\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "        self.model_input = None\n",
    "        \n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        \n",
    "        self._build()\n",
    "    \n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "    \n",
    "    \n",
    "    \"\"\" \n",
    "    ------------\n",
    "    Encoder Part \n",
    "    ------------\n",
    "    \"\"\"\n",
    "    \n",
    "    def _build_encoder(self):\n",
    "        encoder_input = Input(shape=self.input_shape, name = \"Encoder_Input\")\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"Encoder\")\n",
    "    \n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        x = encoder_input\n",
    "        \n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "    \n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        conv_layer = Conv2D(\n",
    "            filters = self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides = self.conv_strides[layer_index],\n",
    "            padding = \"same\",\n",
    "            name=f\"Encoder_Conv_Layer_{layer_index + 1}\")\n",
    "        x = conv_layer(x) #apply the new conv to x -> Convultion with kernels give multiple 2D Arrays\n",
    "        x = ReLU(name=f\"Encoder_ReLU_{layer_index+1}\")(x) # apply a ReLU activation to x\n",
    "        x = BatchNormalization(name=f\"Encoder_BN_{layer_index+1}\")(x) # apply Batch Normalization to x (less overfitting-problems, no vanishing Gradient or exploding Gradient)\n",
    "        return x\n",
    "                               \n",
    "    def _add_bottleneck(self, x):\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:] # Ignore the first dim, which is the batch size\n",
    "        x = Flatten(name=\"Encoder_Flatten\")(x) #Flatten Data\n",
    "        x = Dense(self.latent_space_dim, name=\"Encoder_Output\")(x) #Apply a Dense Layer for the latent space to x11\n",
    "        return x\n",
    "        \n",
    "    \"\"\"\n",
    "    ------------\n",
    "    Decoder Part \n",
    "    ------------\n",
    "    \"\"\"\n",
    "    \n",
    "    def _build_decoder(self):\n",
    "        decoder_input = Input(shape=self.latent_space_dim, name=\"Decoder_Input\")\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = Reshape(self._shape_before_bottleneck, name=\"Decoder_Reshape_Layer\")(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"Decoder\")\n",
    "    \n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # Product of the dimensions before the latent space -> Size of the flattened data before Latent Space\n",
    "        dense_layer = Dense(num_neurons, name=\"Decoder_Dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "    \n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)): # go backwards trough layers. Ignore the first layer, because we don't need ReLU or BN on it\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)  \n",
    "        return x\n",
    "    \n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"Decoder_conv_transpose_layer_{self._num_conv_layers - layer_index}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"Decoder_ReLU_{self._num_conv_layers - layer_index}\")(x)\n",
    "        x = BatchNormalization(name=f\"Decoder_BN_{self._num_conv_layers - layer_index}\")(x)\n",
    "        return x\n",
    "    \n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters= self.input_shape[-1], # We want to recreate the input shape\n",
    "            kernel_size=self.conv_kernels[0],\n",
    "            strides=self.conv_strides[0],\n",
    "            padding=\"same\",\n",
    "            name=f\"Decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(\"sigmoid\", name=\"Decoder_Output_Sigmoid\")(x)\n",
    "        return output_layer\n",
    "    \n",
    "    \"\"\"\n",
    "    ------------\n",
    "    Autoencoder Part \n",
    "    ------------\n",
    "    \"\"\"\n",
    "    \n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"Autoencoder\")\n",
    "    \n",
    "    def compile_model(self, learning_rate=0.0001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        mse_loss = MeanSquaredError()\n",
    "        self.model.compile(optimizer=optimizer, loss=mse_loss)\n",
    "        \n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        self.model.fit(x_train, \n",
    "                       x_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       shuffle=True\n",
    "                      )\n",
    "     \n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        \n",
    "    \"\"\"\n",
    "    ------------------\n",
    "    Saving and Loading\n",
    "    ------------------\n",
    "    \"\"\"\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "        \n",
    "    \n",
    "    def _create_folder(self, save_folder):\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "    \n",
    "    def _save_parameters(self,save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        \n",
    "        save_path = os.path.join(save_folder,\"parameters.pkl\")\n",
    "        \n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(parameters, f)\n",
    "        \n",
    "    \n",
    "    def _save_weights(self,save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.model.save_weights(save_path)\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = Autoencoder(*parameters)\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.model.load_weights(weights_path)\n",
    "        return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de4101d-569c-4bf5-84a0-4457567544ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder_Input (InputLayer)  [(None, 128, 8, 1)]       0         \n",
      "                                                                 \n",
      " Encoder (Functional)        (None, 2)                 101762    \n",
      "                                                                 \n",
      " Decoder (Functional)        (None, 128, 8, 1)         124417    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,179\n",
      "Trainable params: 225,347\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder_Input (InputLayer)  [(None, 128, 8, 1)]       0         \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_1 (Conv2  (None, 128, 8, 32)       320       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_1 (ReLU)       (None, 128, 8, 32)        0         \n",
      "                                                                 \n",
      " Encoder_BN_1 (BatchNormaliz  (None, 128, 8, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_2 (Conv2  (None, 64, 4, 64)        18496     \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_2 (ReLU)       (None, 64, 4, 64)         0         \n",
      "                                                                 \n",
      " Encoder_BN_2 (BatchNormaliz  (None, 64, 4, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_3 (Conv2  (None, 32, 2, 64)        36928     \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_3 (ReLU)       (None, 32, 2, 64)         0         \n",
      "                                                                 \n",
      " Encoder_BN_3 (BatchNormaliz  (None, 32, 2, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_4 (Conv2  (None, 32, 2, 64)        36928     \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_4 (ReLU)       (None, 32, 2, 64)         0         \n",
      "                                                                 \n",
      " Encoder_BN_4 (BatchNormaliz  (None, 32, 2, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Flatten (Flatten)   (None, 4096)              0         \n",
      "                                                                 \n",
      " Encoder_Output (Dense)      (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,762\n",
      "Trainable params: 101,314\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Decoder_Input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " Decoder_Dense (Dense)       (None, 4096)              12288     \n",
      "                                                                 \n",
      " Decoder_Reshape_Layer (Resh  (None, 32, 2, 64)        0         \n",
      " ape)                                                            \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 32, 2, 64)        36928     \n",
      " r_1 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_ReLU_1 (ReLU)       (None, 32, 2, 64)         0         \n",
      "                                                                 \n",
      " Decoder_BN_1 (BatchNormaliz  (None, 32, 2, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 64, 4, 64)        36928     \n",
      " r_2 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_ReLU_2 (ReLU)       (None, 64, 4, 64)         0         \n",
      "                                                                 \n",
      " Decoder_BN_2 (BatchNormaliz  (None, 64, 4, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 128, 8, 64)       36928     \n",
      " r_3 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_ReLU_3 (ReLU)       (None, 128, 8, 64)        0         \n",
      "                                                                 \n",
      " Decoder_BN_3 (BatchNormaliz  (None, 128, 8, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 128, 8, 1)        577       \n",
      " r_4 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_Output_Sigmoid (Act  (None, 128, 8, 1)        0         \n",
      " ivation)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,417\n",
      "Trainable params: 124,033\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(\n",
    "    input_shape = (128,8,1),\n",
    "    conv_filters=(32,64,64,64),\n",
    "    conv_kernels=(3,3,3,3),\n",
    "    conv_strides=(1,2,2,1),\n",
    "    latent_space_dim=2\n",
    ")\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8279c030-0a94-4149-84ed-9b00bdf9b3bb",
   "metadata": {},
   "source": [
    "## Train the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14aed43-7091-46e9-8d90-21da58efbf2e",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498a1b1b-3908-473d-99d3-750ee43330dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    spectogram_data = np.load(\"data\\spectos.npy\")\n",
    "    song_labels = np.load(\"data\\song_labels.npy\")\n",
    "    position_labels = np.load(\"data\\position_labels.npy\")\n",
    "    print(spectogram_data.shape)\n",
    "    spectogram_data = (spectogram_data.astype(\"float32\")+100) / 100 # Normalize the data\n",
    "    \n",
    "    return spectogram_data, position_labels, song_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06933072-d52e-4ba1-9e45-cc7d8435056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563276, 128, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, y_train_alt = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca206db-8586-4f5b-9be5-b567ba994df7",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f1690c-98cb-4601-9ed6-befddb4b0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, learning_rate, batch_size, epochs):\n",
    "    autoencoder.compile_model(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, epochs)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d668ea-2ac7-4582-895e-7202ec15ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 7s 81ms/step - loss: 0.0556\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1 #has to be increased\n",
    "\n",
    "autoencoder = train(x_train[:2209],LEARNING_RATE, BATCH_SIZE,EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71856853-66eb-452a-980b-7f1eacf53134",
   "metadata": {},
   "source": [
    "## Save the Autoencoder\n",
    "We want to save the trained Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d9fc08-0352-4e84-a6be-e58161f4a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514743e6-ab38-4ca1-90a2-cff481a497b4",
   "metadata": {},
   "source": [
    "The Autoencoder can be loaded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ff1614-c03e-497e-b067-6f38a2408ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder_Input (InputLayer)  [(None, 128, 8, 1)]       0         \n",
      "                                                                 \n",
      " Encoder (Functional)        (None, 2)                 101762    \n",
      "                                                                 \n",
      " Decoder (Functional)        (None, 128, 8, 1)         124417    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,179\n",
      "Trainable params: 225,347\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder_Input (InputLayer)  [(None, 128, 8, 1)]       0         \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_1 (Conv2  (None, 128, 8, 32)       320       \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_1 (ReLU)       (None, 128, 8, 32)        0         \n",
      "                                                                 \n",
      " Encoder_BN_1 (BatchNormaliz  (None, 128, 8, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_2 (Conv2  (None, 64, 4, 64)        18496     \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_2 (ReLU)       (None, 64, 4, 64)         0         \n",
      "                                                                 \n",
      " Encoder_BN_2 (BatchNormaliz  (None, 64, 4, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_3 (Conv2  (None, 32, 2, 64)        36928     \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_3 (ReLU)       (None, 32, 2, 64)         0         \n",
      "                                                                 \n",
      " Encoder_BN_3 (BatchNormaliz  (None, 32, 2, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Conv_Layer_4 (Conv2  (None, 32, 2, 64)        36928     \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Encoder_ReLU_4 (ReLU)       (None, 32, 2, 64)         0         \n",
      "                                                                 \n",
      " Encoder_BN_4 (BatchNormaliz  (None, 32, 2, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Encoder_Flatten (Flatten)   (None, 4096)              0         \n",
      "                                                                 \n",
      " Encoder_Output (Dense)      (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,762\n",
      "Trainable params: 101,314\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Decoder_Input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " Decoder_Dense (Dense)       (None, 4096)              12288     \n",
      "                                                                 \n",
      " Decoder_Reshape_Layer (Resh  (None, 32, 2, 64)        0         \n",
      " ape)                                                            \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 32, 2, 64)        36928     \n",
      " r_1 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_ReLU_1 (ReLU)       (None, 32, 2, 64)         0         \n",
      "                                                                 \n",
      " Decoder_BN_1 (BatchNormaliz  (None, 32, 2, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 64, 4, 64)        36928     \n",
      " r_2 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_ReLU_2 (ReLU)       (None, 64, 4, 64)         0         \n",
      "                                                                 \n",
      " Decoder_BN_2 (BatchNormaliz  (None, 64, 4, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 128, 8, 64)       36928     \n",
      " r_3 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_ReLU_3 (ReLU)       (None, 128, 8, 64)        0         \n",
      "                                                                 \n",
      " Decoder_BN_3 (BatchNormaliz  (None, 128, 8, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " Decoder_conv_transpose_laye  (None, 128, 8, 1)        577       \n",
      " r_4 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " Decoder_Output_Sigmoid (Act  (None, 128, 8, 1)        0         \n",
      " ivation)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,417\n",
      "Trainable params: 124,033\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder2 = Autoencoder.load(\"model\")\n",
    "autoencoder2.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
