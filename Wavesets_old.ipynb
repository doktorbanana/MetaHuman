{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab5e0cd-f754-4481-a167-13b6872f7774",
   "metadata": {},
   "source": [
    "# Transform collected YouTube Files to Trainingsdata\n",
    "We want to use two kinds of trainingdata. First we want to split every song in junks of circa 0.5 seconds and use them as trainingsdata to generate new junks. These junks get sorted in a 2 dimensional field by our autoencoder. The structure of a song can then be imagened as a movement trough the 2 dimensional field. We will store these \"movements\", i.e. a list of coordinates and use these lists as trainingsdata for another network. Finally we want to be able to generate new \"movements\", i.e. new sequences of waveset-junks on the one hand and the corresponding junks themselves on the other hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c497dc-be01-47ce-89c8-d8060758f4f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Wavesets\n",
    "Every track from the training data gets split in wavesets with a duration of aprox. 0.2 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b07b5f0-8af1-4c80-8cfd-3cc7236356b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "from IPython.display import display, Audio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b16153b-6909-40a3-923b-87b226c54d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43b2ae-170e-4496-8faa-0ff65178b891",
   "metadata": {},
   "source": [
    "### Loading data (demo track):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75627e6d-ffb6-403a-a722-c48805f52662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% loaded. Currently loading file:H:\\Musik\\CD-Sammlung wavs\\Music\\Wes Montgomery\\Fusion! Wes Montgomery With Strings\\13 Baubles, Bangles And Beads.wavavwavOf The Mor.wav's Book.wavul Husar.wavhing In.wavavav\r"
     ]
    }
   ],
   "source": [
    "folder_path = 'H:\\Musik\\CD-Sammlung wavs\\Music'\n",
    "paths = librosa.util.find_files(folder_path, ext=['wav']) \n",
    "songs = []\n",
    "\n",
    "for i,path in enumerate(paths): \n",
    "    data, sr = librosa.load(path, sr = None, mono = True)\n",
    "    print(f\"{((i+1)/len(paths)) * 100}% loaded.\" + f\" Currently loading file:{path}\", end='\\r')\n",
    "    songs.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b52df5b-fa95-4e5a-b85d-46cc73e5f2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_songs = len(paths)\n",
    "num_of_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3ad63-9c16-4a69-b441-f4116eb565e6",
   "metadata": {},
   "source": [
    "### Waveset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f077b894-5632-4c4d-bf54-92bd14454ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavesets:\n",
    "    def __init__(self, audio_data, sample_rate):\n",
    "            self.data = audio_data\n",
    "            self.sr = sample_rate\n",
    "    \n",
    "    def get_splitPoints(self, data):\n",
    "        split_points = np.argwhere(\n",
    "        (np.sign(data[:-1])==-1) & (np.sign(data[1:])==1)\n",
    "        )\n",
    "        return split_points\n",
    "    \n",
    "    def plot_wavesets(self, data, split_points, plot_range):\n",
    "        data_range = data[plot_range[0]:plot_range[1]]\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(data_range)\n",
    "        plt.hlines(0.0, plot_range[0], plot_range[1], color='r')\n",
    "        plt.vlines(split_points[(plot_range[0]<split_points) & (split_points<plot_range[1])], data_range.max(), data_range.min(), color='g')\n",
    "        plt.xlabel(\"samples\")\n",
    "        plt.ylabel(\"amplitude\")\n",
    "        plt.title(\"Wavesets\")\n",
    "        plt.show();\n",
    "        \n",
    "    def resize_splits(self, splits, min_size):\n",
    "        new_splits = []\n",
    "        last_split = 0\n",
    "        for split in splits:\n",
    "            if (split - last_split) > min_size:\n",
    "                last_split = split\n",
    "                new_splits.append(split)\n",
    "        return np.array(new_splits)\n",
    "    \n",
    "\n",
    "    def generate_wavesets(self, data, split_points):\n",
    "        wavesets = []\n",
    "        # we iterate over split points 2 times: once with no offset\n",
    "        # and a 2nd time with an offset of 1 which gives us\n",
    "        # the start and the end - zip allows us to iterate\n",
    "        # over a collection of arrays in parallel\n",
    "        for start, end in zip(split_points[:-1, 0], split_points[1:, 0]):\n",
    "            wavesets.append(data[start:end+1])\n",
    "            \n",
    "        return wavesets\n",
    "    \n",
    "    def get_Wavesets(self, min_size):\n",
    "        split_points = self.get_splitPoints(self.data)\n",
    "        split_points = self.resize_splits(split_points, min_size)\n",
    "        #self.plot_wavesets(data, split_points, plot_range=[0, self.sr * 60 * 7])\n",
    "        wavesets = self.generate_wavesets(self.data, split_points)\n",
    "        return wavesets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15e9cc-911e-41c0-90bb-54b1784c50ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate Wavesets\n",
    "We can now generate all Wavesets. Later we want to be able to reconstruct the position of each waveset in the song. For this, we store how many wavesets each song is split into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7acbd3c6-f0ec-4eba-89e2-a69e7e11510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of songs splitted into wavesetsnto wavesetss\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(songs)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% of songs splitted into wavesets\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39masarray(num_of_ws_per_song)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mnum_of_ws_per_song\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "all_wavesets = []\n",
    "num_of_ws_per_song = []\n",
    "\n",
    "for i,song in enumerate(songs):\n",
    "    wavesets = Wavesets(song, sr).get_Wavesets(sr/2) # The variable \"wavesets\" is a list of np-arrays (with the amplitudes stored in it).\n",
    "    all_wavesets.extend(list(wavesets))  # all wavesets is a list of all wavesets\n",
    "    num_of_ws_per_song.append(len(wavesets))\n",
    "    print(f\"{((i+1)/len(songs)) * 100}% of songs splitted into wavesets\", end=\"\\r\")\n",
    "\n",
    "np.asarray(num_of_ws_per_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bde13-9b49-40dd-b964-05ba70b4dc5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Padding: Resize Wavesets\n",
    "It's easier to work with arrays of the same size. The wavesets do not have the exact same size at the moment, because the zero-crossing is a contigent feature. We will fill the shorter waveset-arrays with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24d9ab-1b9b-49f5-b7bd-0fd4229db224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.763994996360347% of wavesets padded......\r"
     ]
    }
   ],
   "source": [
    "def find_max_list(list):\n",
    "    list_len = [len(i) for i in list]\n",
    "    max_len = max(list_len)\n",
    "    return max_len\n",
    "\n",
    "max_len_ws = find_max_list(all_wavesets)\n",
    "\n",
    "for index, ws in enumerate(all_wavesets):\n",
    "    missing_items = max_len_ws - len(ws)\n",
    "    all_wavesets[index] = np.pad(all_wavesets[index], (0, missing_items), 'constant', constant_values=(0,0))\n",
    "    print(f\"{((index+1)/len(all_wavesets)) * 100}% of wavesets padded.\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa31f8c-9272-4bf1-a682-55f0b93ec037",
   "metadata": {},
   "source": [
    "### Spectograms of Wavesets\n",
    "We're going to create spectograms of each Waveset. We can use a mel-spectogram or a normal spectogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd25391-8a0b-4235-b6c7-98b1d9e4309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_log_spectogram(pcm_data, n_fft, hop_length, win_length):\n",
    "    stft = librosa.stft(pcm_data, n_fft=n_fft, hop_length=hop_length, win_length=win_length)[:-1]\n",
    "    spectogram = np.abs(stft)\n",
    "    log_spectogram = librosa.amplitude_to_db(spectogram)\n",
    "    return log_spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fbb24c-d887-4072-af64-0048388770e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectogram(pcm_data, bins, hops, winl):\n",
    "        spectogram = librosa.feature.melspectrogram(y=pcm_data, sr=sr, hop_length=hops, win_length=winl, n_fft=bins)\n",
    "        spectogram = librosa.amplitude_to_db(spectogram)\n",
    "        return spectogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89b0fe-75c6-4e4d-b4b3-89a0feee5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LENGTH = int(sr/30)\n",
    "HOP_LENGTH = int(sr/60)\n",
    "N_FFT = int(sr/20)\n",
    "\n",
    "all_wavesets_specto = []\n",
    "\n",
    "for i, ws in enumerate(all_wavesets):\n",
    "    waveset_specto = extract_mel_spectogram(ws, N_FFT, HOP_LENGTH, WIN_LENGTH)\n",
    "    all_wavesets_specto.append(waveset_specto)\n",
    "    print(f\"{((i+1)/len(all_wavesets))*100}% of spectograms extracted.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73160a61-4f0f-443a-94bd-4358105b08cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can look at the spectogram of a random waveset to see that everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2005d4-7810-42bf-9a7f-8a68fb16990e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "librosa.display.specshow(\n",
    "    all_wavesets_specto[np.random.randint(0,len(all_wavesets_specto))],\n",
    "    x_axis='time',\n",
    "    y_axis='mel',\n",
    "    sr=sr,\n",
    "    fmax=20000,\n",
    "    hop_length=HOP_LENGTH,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83769e90-8b1c-4d00-9f46-0504b93cccd4",
   "metadata": {},
   "source": [
    "We do not normalize our samples, because we want to preserve the loudness of each waveset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0554a0d-1ee1-4ade-9c79-1fc0ee3473b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Song-Label for Wavesets\n",
    "We need another array that stores the information which waveset belongs to which song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598a978-3a3d-4907-a709-a733745c2147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song_labels = np.empty(len(all_wavesets_specto))\n",
    "\n",
    "start_ws = 0\n",
    "stop_ws = 0\n",
    "\n",
    "for i, num_of_ws in enumerate(num_of_ws_per_song):\n",
    "    stop_ws += num_of_ws\n",
    "    song_labels[start_ws : stop_ws] = i\n",
    "    start_ws += num_of_ws\n",
    "    print(f\"{((i+1)/len(num_of_ws_per_song)) * 100}% done\", end = \"\\r\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155638b-a7bb-4bd3-8a87-62f2605bfd3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create position data\n",
    "We also want to know, at which position in the song a waveset occured. For this we split the song in 4 parts and create a label 0,1,2 or 3 for each waveset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c78c77-70ba-4777-9279-6d3dc30413a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "position_labels = np.empty(len(all_wavesets_specto))\n",
    "\n",
    "start_ws = 0\n",
    "stop_ws = 0\n",
    "\n",
    "for i, num_of_ws in enumerate(num_of_ws_per_song):\n",
    "    for j in range(4):\n",
    "        stop_ws += int((num_of_ws/4))\n",
    "        position_labels[start_ws : stop_ws] = j+1\n",
    "        start_ws = stop_ws\n",
    "    print(f\"{((i+1)/len(num_of_ws_per_song)) * 100}% done\", end = \"\\r\")\n",
    "\n",
    "position_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5854a-1fb9-45cd-9d9e-44289c5b0436",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save Data\n",
    "We save the data on disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04809f4a-4afd-4ceb-a6ec-2a03d6a20ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data\\spectos.npy\"\n",
    "np.save(save_path,all_wavesets_specto)\n",
    "\n",
    "save_path2 = \"data\\song_labels.npy\"\n",
    "np.save(save_path2, song_labels)\n",
    "\n",
    "save_path3 = \"data\\position_labels.npy\"\n",
    "np.save(save_path3, position_labels)\n",
    "\n",
    "save_path4 = \"data\\num_of_ws_per_song.npy\"\n",
    "np-save(save_path4, num_of_ws_per_song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
