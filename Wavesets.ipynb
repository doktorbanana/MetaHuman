{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab5e0cd-f754-4481-a167-13b6872f7774",
   "metadata": {},
   "source": [
    "# Transform collected YouTube Files to Trainingsdata\n",
    "We want to use two kinds of trainingdata. First we want to split every song in junks of circa 0.5 seconds and use them as trainingsdata to generate new junks. These junks get sorted in a 2 dimensional field by our autoencoder. The structure of a song can then be imagened as a movement trough the 2 dimensional field. We will store these \"movements\", i.e. a list of coordinates and use these lists as trainingsdata for another network. Finally we want to be able to generate new \"movements\", i.e. new sequences of waveset-junks on the one hand and the corresponding junks themselves on the other hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c497dc-be01-47ce-89c8-d8060758f4f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wavesets\n",
    "Every track from the training data gets split in wavesets with a duration of aprox. 0.2 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b07b5f0-8af1-4c80-8cfd-3cc7236356b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "from IPython.display import display, Audio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b16153b-6909-40a3-923b-87b226c54d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43b2ae-170e-4496-8faa-0ff65178b891",
   "metadata": {},
   "source": [
    "### Loading data (demo track):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75627e6d-ffb6-403a-a722-c48805f52662",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'demoData'\n",
    "paths = librosa.util.find_files(folder_path, ext=['wav']) \n",
    "songs = []\n",
    "\n",
    "for path in paths: \n",
    "    data, sr = librosa.load(path, sr = None, mono = True)\n",
    "    songs.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3ad63-9c16-4a69-b441-f4116eb565e6",
   "metadata": {},
   "source": [
    "### Waveset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f077b894-5632-4c4d-bf54-92bd14454ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavesets:\n",
    "    def __init__(self, audio_data, sample_rate):\n",
    "            self.data = audio_data\n",
    "            self.sr = sample_rate\n",
    "    \n",
    "    def get_splitPoints(self, data):\n",
    "        split_points = np.argwhere(\n",
    "        (np.sign(data[:-1])==-1) & (np.sign(data[1:])==1)\n",
    "        )\n",
    "        return split_points\n",
    "    \n",
    "    def plot_wavesets(self, data, split_points, plot_range):\n",
    "        data_range = data[plot_range[0]:plot_range[1]]\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(data_range)\n",
    "        plt.hlines(0.0, plot_range[0], plot_range[1], color='r')\n",
    "        plt.vlines(split_points[(plot_range[0]<split_points) & (split_points<plot_range[1])], data_range.max(), data_range.min(), color='g')\n",
    "        plt.xlabel(\"samples\")\n",
    "        plt.ylabel(\"amplitude\")\n",
    "        plt.title(\"Wavesets\")\n",
    "        plt.show();\n",
    "        \n",
    "    def resize_splits(self, splits, min_size):\n",
    "        new_splits = []\n",
    "        last_split = 0\n",
    "        for split in splits:\n",
    "            if (split - last_split) > min_size:\n",
    "                last_split = split\n",
    "                new_splits.append(split)\n",
    "        return np.array(new_splits)\n",
    "    \n",
    "\n",
    "    def generate_wavesets(self, data, split_points):\n",
    "        wavesets = []\n",
    "        # we iterate over split points 2 times: once with no offset\n",
    "        # and a 2nd time with an offset of 1 which gives us\n",
    "        # the start and the end - zip allows us to iterate\n",
    "        # over a collection of arrays in parallel\n",
    "        for start, end in zip(split_points[:-1, 0], split_points[1:, 0]):\n",
    "            wavesets.append(data[start:end+1])\n",
    "            \n",
    "        return wavesets\n",
    "    \n",
    "    def get_Wavesets(self, min_size):\n",
    "        split_points = self.get_splitPoints(self.data)\n",
    "        split_points = self.resize_splits(split_points, min_size)\n",
    "        #self.plot_wavesets(data, split_points, plot_range=[0, self.sr * 60 * 7])\n",
    "        wavesets = self.generate_wavesets(self.data, split_points)\n",
    "        return wavesets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15e9cc-911e-41c0-90bb-54b1784c50ac",
   "metadata": {},
   "source": [
    "### Generate Wavesets\n",
    "We can now generate all Wavesets. Later we want to be able to reconstruct the position of each waveset in the song. For this, we store how many wavesets each song is split into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7acbd3c6-f0ec-4eba-89e2-a69e7e11510a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([919, 641])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wavesets = []\n",
    "num_of_ws_per_song = []\n",
    "\n",
    "for song in songs:\n",
    "    wavesets = Wavesets(song, sr).get_Wavesets(sr/2) # The variable \"wavesets\" is a list of np-arrays (with the amplitudes stored in it).\n",
    "    all_wavesets.extend(list(wavesets))  # all wavesets is a list of all wavesets\n",
    "    num_of_ws_per_song.append(len(wavesets))\n",
    "\n",
    "np.asarray(num_of_ws_per_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bde13-9b49-40dd-b964-05ba70b4dc5c",
   "metadata": {},
   "source": [
    "### Padding: Resize Wavesets\n",
    "It's easier to work with arrays of the same size. The wavesets do not have the exact same size at the moment, because the zero-crossing is a contigent feature. We will fill the shorter waveset-arrays with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d24d9ab-1b9b-49f5-b7bd-0fd4229db224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_list(list):\n",
    "    list_len = [len(i) for i in list]\n",
    "    max_len = max(list_len)\n",
    "    return max_len\n",
    "\n",
    "max_len_ws = find_max_list(all_wavesets)\n",
    "\n",
    "for index, ws in enumerate(all_wavesets):\n",
    "    missing_items = max_len_ws - len(ws)\n",
    "    all_wavesets[index] = np.pad(all_wavesets[index], (0, missing_items), 'constant', constant_values=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa31f8c-9272-4bf1-a682-55f0b93ec037",
   "metadata": {},
   "source": [
    "### Spectograms of Wavesets\n",
    "We're going to create spectograms of each Waveset. We can use a mel-spectogram or a normal spectogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd25391-8a0b-4235-b6c7-98b1d9e4309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_log_spectogram(pcm_data, n_fft, hop_length, win_length):\n",
    "    stft = librosa.stft(pcm_data, n_fft=n_fft, hop_length=hop_length, win_length=win_length)[:-1]\n",
    "    spectogram = np.abs(stft)\n",
    "    log_spectogram = librosa.amplitude_to_db(spectogram)\n",
    "    return log_spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fbb24c-d887-4072-af64-0048388770e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectogram(pcm_data, bins, hops, winl):\n",
    "        spectogram = librosa.feature.melspectrogram(y=pcm_data, sr=sr, hop_length=hops, win_length=winl, n_fft=bins)\n",
    "        spectogram = librosa.amplitude_to_db(spectogram)\n",
    "        return spectogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89b0fe-75c6-4e4d-b4b3-89a0feee5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LENGTH = int(sr/30)\n",
    "HOP_LENGTH = int(sr/40)\n",
    "N_FFT = int(sr/20)\n",
    "\n",
    "all_wavesets_specto = []\n",
    "\n",
    "for ws in all_wavesets:\n",
    "    waveset_specto = extract_mel_spectogram(ws, N_FFT, HOP_LENGTH, WIN_LENGTH)\n",
    "    all_wavesets_specto.append(waveset_specto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73160a61-4f0f-443a-94bd-4358105b08cd",
   "metadata": {},
   "source": [
    "We can look at the spectogram of a random waveset to see that everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2005d4-7810-42bf-9a7f-8a68fb16990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(\n",
    "    all_wavesets_specto[np.random.randint(0,len(all_wavesets_specto))],\n",
    "    x_axis='time',\n",
    "    y_axis='mel',\n",
    "    sr=sr,\n",
    "    fmax=20000,\n",
    "    hop_length=HOP_LENGTH,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83769e90-8b1c-4d00-9f46-0504b93cccd4",
   "metadata": {},
   "source": [
    "We do not normalize our samples, because we want to preserve the loudness of each waveset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5854a-1fb9-45cd-9d9e-44289c5b0436",
   "metadata": {},
   "source": [
    "### Save spectograms\n",
    "We save the data on disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04809f4a-4afd-4ceb-a6ec-2a03d6a20ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data\\spectos.npy\"\n",
    "np.save(save_path,all_wavesets_specto)\n",
    "\n",
    "save_path2 = \"data\\wsPerSong.npy\"\n",
    "np.save(save_path2, num_of_ws_per_song)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cf6b0-13b0-4ef5-841e-6b38422d033c",
   "metadata": {},
   "source": [
    "The data can be loaded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297e0fb-2f66-4bfc-950a-dae579b17115",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data1 = np.load(\"data\\spectos.npy\")\n",
    "print(loaded_data1)\n",
    "loaded_data2 = np.load(\"data\\wsPerSong.npy\")\n",
    "print(loaded_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ace10f-fa2d-4a4e-b6d9-6ea13a7d730b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
