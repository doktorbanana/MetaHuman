{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc3ca43-24e1-4445-9565-0eb669a0a422",
   "metadata": {},
   "source": [
    "# Data Crawling\n",
    "For the training of ML1 and ML2 we need data. In this project the selection of training data is an important creative decision. Since Machine Learning algorithms try to minimize some kind of error, it is crutial how this error is defined. The networks will try to produce sound as close as possible to their training data. Thus the produced sounds will be very different, for different training data. As stated above, we want to give as many creative decision as possible to machines, since the goal is a meta-human sound. Therefor we've decided to use yet another machine learning algorithm to select the training data: YouTube's recomendation algorithm.\n",
    "\n",
    "The following code controls the mouse of the users system to collect YouTube links. For this the user has to open a YouTube video on the platform on a Full-HD screen. The code will automatically click on the next recomendation and copy the URL. That can be used to download the sound of the YouTube video, e.g. via the program MediaHuman (https://www.mediahuman.com/de/).\n",
    "\n",
    "WARNING: This code controls the mouse! You can only stop it by pressing and holding down the space bar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3814c-ca2d-4cdc-b2a4-57cb49d11319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mouse, keyboard\n",
    "import time\n",
    "\n",
    "def click_next_video():\n",
    "    mouse.move(504, 700)\n",
    "    time.sleep(5)\n",
    "    mouse.click()\n",
    "    time.sleep(2)\n",
    "    keyboard.send(\"shift+n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "def copy_link():\n",
    "    mouse.move(504, 50)\n",
    "    mouse.click()\n",
    "    time.sleep(0.6)\n",
    "    keyboard.send(\"ctrl+c\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # while True:\n",
    "    #    print(mouse.get_position())\n",
    "    time.sleep(5) # time to change the window to Youtube\n",
    "\n",
    "    for i in range(1000):\n",
    "        if keyboard.is_pressed(\"space\"):\n",
    "            exit()\n",
    "        copy_link()\n",
    "        click_next_video()\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d08e9-e9fc-43ae-b46b-9c6bb285000a",
   "metadata": {},
   "source": [
    "During testing of this project, we've recognized that songs with full instrumentation are too complex. Rather we want to use single instruments or vocals. Again, we don't need a human to decide which signal counts as \"vocals\". We can use another machine learning algorithm to extract stems from the downloaded song. We used spleeter for this (more info here: https://github.com/deezer/spleeter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126185a-8f0a-4b57-b844-48f14b7685b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from spleeter.separator import Separator\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    num = 50\n",
    "    step_size = 450\n",
    "\n",
    "    separator = Separator('spleeter:4stems')\n",
    "    path = os.path.join('demo_data/', \"*\")\n",
    "    list_of_files = glob.glob(path)\n",
    "    start_time = time.time()\n",
    "\n",
    "    list_of_files = list_of_files[num:num+step_size]\n",
    "\n",
    "    for i,file in enumerate(list_of_files):\n",
    "        separator.separate_to_file(file,\n",
    "                                   \"demo_data/stems\",\n",
    "                                   filename_format=\"{instrument}/{instrument}\" + str(i+num) + \".{codec}\",\n",
    "                                   synchronous=False)\n",
    "    separator.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635f860-6c9e-47be-a30b-541e42f28c29",
   "metadata": {},
   "source": [
    "Spleeter splits each song in 4 stems: vocals, bass, drums and other. Intrestingly the results are not always perfect. For example on a song that has flutes, but no vocals, the neural network seperates the flutes and writes the data on the vocal track. But the network is not always trying to find a vocals stem. It seems to be able, to recognize if there are no vocals in some cases. On songs without a strong leading voice, the vocals file can be empty.\n",
    "\n",
    "Here we as the programmers have to make a decision which data to keep. As our goal is meta-human music, we want to keep all vocals stems that are not empty. We can keep the machine interpretation of what vocals are, and do not have to correct that with our human interpretation. \n",
    "We delete the empty files (or nearly empty files) in the next step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
