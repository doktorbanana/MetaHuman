{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b6155c-7b4f-4f71-b673-63dba7734a30",
   "metadata": {},
   "source": [
    "# Conversation\n",
    "Now that we've trained and saved two indepedent models with two independent training sets, we want them to talk to each other. In a first step autoencoder1 produces a new song and sends it to autoencoder2 in PCA format. Autoencoder1 plays the audio, while Autoencoder2 analyze it and finds a 2D representation in its latent space. When Autoencoder1 is finished, Autoencoder2 tries to reproduce the song by decoding its latent space representation back to PCA. The process then starts to anew with switched roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0615a77d-77de-4da8-81fa-9cca7c86b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from Variational_Autoencoder_alla_Valerio import VAE\n",
    "from Snippets import Snippets\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee46ac29-9251-4515-899b-976d25d8c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversator:\n",
    "    def __init__(self, snippet_model_path,\n",
    "                 order_model_path,\n",
    "                 partner,\n",
    "                 min_size_fraction,\n",
    "                 hop_length,\n",
    "                 n_fft,\n",
    "                 win_length,\n",
    "                 sample_rate=44100,\n",
    "                 name=\"Valerio\"):\n",
    "        self.name = name\n",
    "\n",
    "        self.min_size_fraction = min_size_fraction\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.n_fft = n_fft\n",
    "        self.sr = sample_rate\n",
    "\n",
    "        self.snippet_generator = Snippets(path=None,\n",
    "                                          min_size_fraction=self.min_size_fraction,\n",
    "                                          win_length=self.win_length,\n",
    "                                          n_fft=self.n_fft,\n",
    "                                          hop_length=self.hop_length)\n",
    "        self.snippet_autoencoder = VAE.load(snippet_model_path)\n",
    "        self.order_autoencoder = VAE.load(order_model_path)\n",
    "\n",
    "        self.partner = partner\n",
    "        self.last_song_heard = None\n",
    "        self.remembered_spectos = None\n",
    "        self.currently_singing = False\n",
    "\n",
    "    \"\"\"\n",
    "    ========\n",
    "      SING\n",
    "    ========\n",
    "    Here we want the model to generate a new song, based on the last song it heard. It should output the PCA-data and\n",
    "    send it to its partner.\n",
    "    \"\"\"\n",
    "\n",
    "    def sing(self, song):\n",
    "        self.currently_singing = True\n",
    "        self.partner.last_song_heard = song\n",
    "        Audio(song, autoplay=True, rate=self.sr)\n",
    "        duration = song.shape[0] / self.sr\n",
    "        start_time = time.time()\n",
    "        if time.time() > start_time + duration + 1:\n",
    "            print(self.name + \": I'm done singing my song. Did you like it?\")\n",
    "            self.currently_singing = False\n",
    "\n",
    "    def sing_last_heard_song(self):\n",
    "        print(self.name + \": Let me try to sing, what i just heard. DubiSchubiDu...\")\n",
    "        self.sing(self.last_song_heard)\n",
    "\n",
    "    def sing_human_song(self, subfolder):\n",
    "        print(self.name + \": LaLeLu... I'm singing one of the human songs...\")\n",
    "\n",
    "        song_orders_path = os.path.join(\"data_and_models\", subfolder + \"/song_orders.npy\")\n",
    "        song_orders = np.load(song_orders_path)\n",
    "        human_song = song_orders[np.random.randint(0, song_orders.shape[0])]\n",
    "        human_pcm = Snippets.latent_representation_to_pcm(latent_representations=human_song,\n",
    "                                                          model=self.snippet_autoencoder,\n",
    "                                                          hop_length=self.hop_length,\n",
    "                                                          n_fft=self.n_fft,\n",
    "                                                          win_length=self.win_length)\n",
    "\n",
    "        self.sing(human_pcm)\n",
    "\n",
    "    def sing_machine_song(self):\n",
    "        # HAS TO BE IMPLEMENTED\n",
    "        print(\"BriiBrazzzFuaazz... I'm singing a machine song.\")\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    ========\n",
    "     Listen\n",
    "    ========\n",
    "    Here we want the model to prepare a new song, based on the song it just received.\n",
    "    \"\"\"\n",
    "\n",
    "    def listen(self):\n",
    "        print(self.name + \": Ohhuu... I'm listening to nice machine music...\")\n",
    "        self.song_to_sing = self.pcm_to_pcm(self.last_song_heard)\n",
    "\n",
    "    def pcm_to_pcm(self, pcm_data):\n",
    "        spectos = self.pcm_to_spectos(pcm_data)\n",
    "        new_pcm = Snippets.specto_to_pcm(model=self.snippet_autoencoder,\n",
    "                                         data=spectos,\n",
    "                                         hop_length=self.hop_length,\n",
    "                                         n_fft=self.hop_length,\n",
    "                                         win_length=self.win_length)\n",
    "        return new_pcm\n",
    "\n",
    "    def pcm_to_spectos(self, pcm_data):\n",
    "        self.snippet_generator.data = pcm_data\n",
    "        spectos = self.snippet_generator.get_snippet_spectos()\n",
    "        self.remembered_spectos.extend(spectos)\n",
    "        return spectos\n",
    "\n",
    "    \"\"\"\n",
    "    ==============\n",
    "        Dream\n",
    "    ==============\n",
    "    Here we want the model to add the heard songs to it's training data.\n",
    "    \"\"\"\n",
    "\n",
    "    def dream(self, batch_size=1, epochs=20):\n",
    "        print(self.name + \": ZzzZzz I'm dreaming about all the music i've heard...\")\n",
    "\n",
    "        # Retrain the Snippet-Autoencoder\n",
    "        x_train = np.asarray(self.remembered_spectos)\n",
    "        self.snippet_autoencoder.train(x_train, x_train, batch_size=batch_size, num_epochs=epochs)\n",
    "\n",
    "        # Retrain the Song_Order_Autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710117da-1b6c-40e1-8466-165036744796",
   "metadata": {},
   "source": [
    "First we need to load the two autoencoders and two corresponding SoundGenerators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d4537-cd3f-4a46-b19e-6dbca7595b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder1_name=\"VAE_2D_1.0_24_2500samples\"\n",
    "autoencoder2_name=\"VAE_2D_1.0_24_2500samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcc9f5-e3ab-41eb-8669-8136987b49a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
